{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "import os, re, operator, warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = nlp.Defaults.stop_words\n",
    "for word in nlp.Defaults.stop_words:\n",
    "    lexeme = nlp.vocab[word]\n",
    "    lexeme.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'The Delhi Traffic Police (DTP) has roped in Bollywood actors Anushka Sharma and Varun Dhawan for a series of video messages on safe driving.The actors were in Delhi for the shoot of their upcoming film \"Sui Dhaaga-Made In India\". They shot at Chandni Chowk and Shankar Market amid tight security, a senior traffic police officer said.\"We wanted to do an event with them to promote safe driving but they were on a tight schedule. We have recorded their video messages that will be uploaded on our Twitter handle,\" the officer said.In a video message that was uploaded today on the traffic polices Twitter handle, Anushka can be seen urging people to ride two-wheelers wearing helmets.\"Delhi Police does a lot of things for our safety. Your life is important for you and your loved ones. You should drive safely. While riding a motorcycle, you should always wear a helmet,\" the actor said in the message.WATCH VIDEO:pic.twitter.com/VzV1ezCtac— Delhi Traffic Police (@dtptraffic) April 2, 2018Varuns video message is likely to be uploaded on the micro-blogging site by the traffic police tomorrow.Interestingly, in November last year the actor was issued an e-challan by the Mumbai Traffic Police for clicking a selfie with a fan while leaning out of his car that was stuck at a traffic signal. Varun later apologised for the same.\"Sui Dhaaga - Made In India\" went on floors in January this year and will hit the theatres on Gandhi Jayanti. The film is being directed by Sharat Katariya, who has previously helmed YRFs \"Dum Laga Ke Haisha\", while Maneesh Sharma is producing the project that will endorse the message of Make In India.READ | Vadodara Police Just Shared Priya Prakash Varrier’s Poster And It’s Going Viral. Here’s WhyEarlier, the DTP has invited celebs like Arjun Kapoor, Kangana Ranaut, Sonam Kapoor, Sonakshi Sinha and Kapil Sharma among others to dole out road safety lessons to Delhiites.In 2016, 1,548 fatal accidents were reported in which 1,591 people lost their lives. In 2017, the number of such accidents was 1,474 and 1,505 people were killed, according to the Delhi Traffic Police statistics.Till March 15 this year, 239 accidents were reported in which 248 persons were killed.'\n",
    "data = 'the student they make up a bit slower than the OnePlus 5 this young male is late for his 9 a.m. he kept his notes with a telephoto lens to get back to more important things'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_speech(path,file_format):\n",
    "    import speech_recognition as sr\n",
    "    from pydub import AudioSegment\n",
    "\n",
    "    sound = AudioSegment.from_file(str(path), format=str(file_format))\n",
    "    r = sr.Recognizer()\n",
    "    article_list = []\n",
    "\n",
    "    for i in range(0,int(len(sound)/1000),15):\n",
    "        if(i+15<int(len(sound)/1000)):\n",
    "            cropped = sound[i*1000:(14+i)*1000]\n",
    "            cropped.export(\"file.wav\", format=\"wav\")\n",
    "            with sr.AudioFile('file.wav') as source:\n",
    "                audio = r.record(source)\n",
    "            try:\n",
    "                text = r.recognize_google(audio)\n",
    "    #             article.join(' '+str(text))\n",
    "                article_list.append(text)\n",
    "            except :\n",
    "                text = r.recognize_sphinx(audio)\n",
    "                article_list.append(text)\n",
    "    #             article.join(' '+str(text))\n",
    "\n",
    "    cropped = sound[i*1000:int(len(sound))]\n",
    "    cropped.export(\"file.wav\", format=\"wav\")\n",
    "    with sr.AudioFile('file.wav') as source:\n",
    "        audio = r.record(source)\n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "    #             article.join(' '+str(text))\n",
    "        article_list.append(text)\n",
    "    except :\n",
    "    #     text = r.recognize_sphinx(audio)\n",
    "    #     article_list.append(text)\n",
    "        print('Error')\n",
    "    string = ''\n",
    "    for crop in article_list:\n",
    "        string=string+' '+crop\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = process_speech(\"video.mp4\",\"mp4\")\n",
    "doc = nlp(clean(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit = dict({'cum dumpster':82, 'felch':82, 'cunt':82, 'skullfuck':82, 'Alabama hot pocket':82, 'cock-juggling thundercunt':82,'rusty trombone': 82,'blumpkin':82,'Cleveland S-teamer':82,'cum guzzling cock sucker':81,'glass bottom boat':81,\"suck a fat baby's dick\":81,'skermit':80,'fucking pussy':80,'meat flap':80,'fuck hole':80,'hairy axe wound':79,'up the ass':79, 'assmucus':79,'cumdump':79, 'beef curtain':79, 'moose nuckle':79,'cum chugger':78,'mother fucker':78, 'motherfucking':78, 'roast beef curtains':78, 'fuck':78, 'Roman Helmet':78, 'get some squish':77, 'eat a dick':77, 'clitty litter':77, 'eat hair pie':77, 'bisnotch':77, 'yard cunt punt':77, 'blue waffle':77, 'fist fuck':77, 'bitchass mother fucker':77,'fuck me in the ass with no Vaseline':77,'fuck yo mama':77,'chota bags':77, 'cuntee':77, 'motherfucker':77, 'meat drapes':77,'schlong juice':76, 'bang':76, 'meat tulips':76,     'cum freak':76, 'buggery':76, 'cuntsicle':76,     'fuckmeat':76, 'bust a load':76, 'butt fuck':76, 'GMILF':76, 'cock snot':76, 'shit fucker':76, 'sausage queen':76, 'fucktoy':76, 'dick hole':76, 'cock pocket':76, 'lick my froth':76, 'cunt-struck':76, 'cockbag':76,  'gangbang':75, 'pussy fart':75, 'ham flap':75, 'cum guzzler':75, 'squeeze a steamer':75, 'ass fuck':75, 'hoitch':75, 'cunt hole':75, 'clit licker':75, 'anal impaler':75, 'dick sucker':75, 'baby arm':75, 'smoke a sausage':75, 'Cuntasaurus rex':75, 'cunt face':75, 'buckle buffer':75,     'slich':75, 'fubugly':   75,     'man chowder':  75,     'key hole':  75,     'cocksucker':  75,     'get redwings':  75,     'hemped up':  75,     'smoke pole' :  75,     'like fuck' : 75,     'feedbag material':  75,     'eat fur pie':  74,     'analconda': 74 ,    'soggy muffin' : 74,     'suck a dick' : 74, 'nut butter':   74 ,    'fuck-bitch':  74 ,    \"pull (one's) dick\" :  74,     'get brain':  74  ,   'sweet dick daddy with the candy balls' : 74, 'get in pants':  74  ,   'felcher':  74  ,   'fuck puppet' : 74})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explicit['fuck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, article = [], []\n",
    "explicit_content = []\n",
    "for w in doc:\n",
    "    lem = w.lemma_\n",
    "    if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num and (not lem in stops) and not (w.text in explicit.keys()):  \n",
    "        article.append(w.lemma_)\n",
    "    \n",
    "    if w.text == '\\n':\n",
    "        texts.append(article)\n",
    "        article = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not len(texts):\n",
    "    articles = []\n",
    "    phrases = gensim.models.phrases.Phrases(article)\n",
    "    bigram = gensim.models.phrases.Phraser(phrases)\n",
    "    articles.append(bigram[article])\n",
    "    dictionary = Dictionary(articles)\n",
    "    corpus = [dictionary.doc2bow(text) for text in articles]\n",
    "    texts = articles\n",
    "else:\n",
    "    phrases = gensim.models.phrases.Phrases(texts)\n",
    "    bigram = gensim.models.phrases.Phraser(phrases)\n",
    "    texts = [bigram[line] for line in texts]\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdpmodel = HdpModel(corpus=corpus, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdpmodel.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdptopics = hdpmodel.show_topics(formatted=False)\n",
    "# hdptopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_texts(fname):\n",
    "    \"\"\"\n",
    "    Function to build tokenized texts from file\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    fname: File to be read\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    yields preprocessed line\n",
    "    \"\"\"\n",
    "    yield gensim.utils.simple_preprocess(fname, deacc=True, min_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = list(build_texts(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_top_model(threshold):\n",
    "    \"\"\"\n",
    "    Since LDAmodel is a probabilistic model, it comes up different topics each time we run it. To control the\n",
    "    quality of the topic model we produce, we can see what the interpretability of the best topic is and keep\n",
    "    evaluating the topic model until this threshold is crossed. \n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lm: Final evaluated topic model\n",
    "    top_topics: ranked topics in decreasing order. List of tuples\n",
    "    \"\"\"\n",
    "    top_topics = [(0, 0)]\n",
    "    while top_topics[0][1] < threshold:\n",
    "        lm = LdaModel(corpus=corpus, id2word=dictionary)\n",
    "        coherence_values = {}\n",
    "        for n, topic in lm.show_topics(num_topics=-1, formatted=False):\n",
    "            topic = [word for word, _ in topic]\n",
    "            cm = CoherenceModel(topics=[topic], texts=texts, dictionary=dictionary, window_size=10)\n",
    "            coherence_values[n] = cm.get_coherence()\n",
    "        top_topics = sorted(coherence_values.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        print(top_topics[0][1])\n",
    "    return lm, top_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7062226725619165\n"
     ]
    }
   ],
   "source": [
    "lm, top_topics = ret_top_model(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(47, 0.7062226725619165),\n",
       " (99, 0.4120816796219134),\n",
       " (0, 0.4120816796219133),\n",
       " (1, 0.4120816796219133),\n",
       " (2, 0.4120816796219133)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_lsi_topics = [[word for word, prob in lm.show_topic(topicid)] for topicid, c_v in top_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a.m.', 'lens', 'note', 'male', 'young', 'oneplus', 'thing', 'telephoto', 'slow', 'important', 'student', 'bit', 'late'}\n"
     ]
    }
   ],
   "source": [
    "topics=set()\n",
    "for topic in lda_lsi_topics:\n",
    "    for string in topic:\n",
    "        topics.add(string)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"key_tags\": [\"a.m.\", \"lens\", \"note\", \"male\", \"young\", \"oneplus\", \"thing\", \"telephoto\", \"slow\", \"important\", \"student\", \"bit\", \"late\", \"9 a.m.\"]}'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_tags = []\n",
    "for key in topics:\n",
    "    key_tags.append(key)\n",
    "for e in doc.ents:\n",
    "    if e.text.lower() not in key_tags:\n",
    "        key_tags.append(e.text.lower())\n",
    "json_format = json.dumps({'key_tags':key_tags})\n",
    "json_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('OnePlus', 'ORG', 'Companies, agencies, institutions, etc.'), ('9 a.m.', 'TIME', 'Times smaller than a day')]\n"
     ]
    }
   ],
   "source": [
    "ents = [(e.text, e.label_,spacy.explain(e.label_)) for e in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the student they make up a bit slower than the OnePlus 5 this young male is late for his 9 a.m. he kept his notes with a telephoto lens to get back to more important things"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
